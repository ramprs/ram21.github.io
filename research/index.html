---
layout: default
title: My Research
---

        <div class="research">
            <h1>Research</h1>
            <p> My research interests lie at the intersection of Computer Vision and Machine Learning, with a focus on building algorithms that can </p>

            <ul>
                <li> explain why they believe what they believe </li>
                <li> truly understand and grasp information from different modalities (vision, language, common sense reasoning) and create other possible scenarios </li>
            </ul>

            <h2>Projects</h2>

            <ul>
                <li> Making Deep Models Interpretable Without Making Interpretable Deep Models </li>
                <p> Deep CNNs have enabled significant breakthroughs for vision, but at the same time they raise important questions about interpretability. To make these models more interpretable we start by (1) proposing a novel class localization method called Gradient-weighted Class Activation Maps (Grad-CAM) which uses gradients to perform localization. (2) Then we combine Grad-CAM with visualizations like Guided Backpropagation to create a novel visualization method called Guided
                Grad-CAM. The resulting visualizations provide intuitive explanations for CNN predictions by showing both what salient features a CNN looks at as well as where it looks. (3) Further, we empirically demonstrate that our visualization technique is highly class-discriminative through human studies. (4) Finally, we show the broad applicability of this visualization technique for not just image classification, but also visual question answering and image captioning, showing how
                to interpret typically uninterpretable deep models. </p>
                <p> Arxiv link and Code coming out soon </p>

                <li> Counting Everyday Objects in Everyday Scenes </li>

                <p> We introduce the problem of counting everyday objects in everyday scenes. While previous works have studied specific counting problems such as pedestrian counting in surveillance videos, or biological cell counting, we are interested in counting common objects in natural scenes. We study this problem in a setup similar to traditional scene understanding problems. Given an image, we consider the task of predicting the counts (or the numerosity) of categories of interest. We study some simple approaches and applications for this counting problem. Our detect approach adapts an object detector to perform counting, while our glance approach regresses to ground truth counts. Our associative subitizing (aso-sub) approach divides an image into regions and regresses to fractional object counts in each region. We create an ensemble (ens) of these counting methods which improves performance. We demonstrate
                counting performance on the PASCAL and MS COCO datasets. We show proof-of-concept applications of our automatic counting methods to 1) improve object detection performance, and 2) visual question answering (on VQA and COCO-QA). </p>
                <p> Arxiv: </p>
                <p> Code: </p>

                <li>

            </ul>

